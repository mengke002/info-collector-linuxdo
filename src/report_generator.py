"""
æ™ºèƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
åŸºäºæ¿å—çš„çƒ­ç‚¹å†…å®¹åˆ†æå’ŒMarkdownæŠ¥å‘Šç”Ÿæˆ
"""
import logging
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone, timedelta

from .database import db_manager
from .llm_client import llm_client
from .config import config


class ReportGenerator:
    """æ™ºèƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.db = db_manager
        self.llm = llm_client
        
        # æŠ¥å‘Šé…ç½®
        self.top_topics_per_category = 30
        self.top_replies_per_topic = 10
        # å¢åŠ å†…å®¹é•¿åº¦é™åˆ¶ä»¥å®¹çº³æ›´å¤šä¸»é¢˜
        self.max_content_length = config.get_llm_config().get('max_content_length', 50000)
    
    def get_beijing_time(self) -> datetime:
        """è·å–å½“å‰åŒ—äº¬æ—¶é—´"""
        return datetime.now(timezone.utc) + timedelta(hours=8)
    
    def _truncate_content(self, content: str, max_length: int = None) -> str:
        """æˆªæ–­å†…å®¹åˆ°æŒ‡å®šé•¿åº¦"""
        if max_length is None:
            max_length = self.max_content_length
        
        if len(content) <= max_length:
            return content
        
        # åœ¨åˆé€‚çš„ä½ç½®æˆªæ–­ï¼Œé¿å…æˆªæ–­åˆ°å¥å­ä¸­é—´
        truncated = content[:max_length]
        
        # å°è¯•åœ¨æœ€åä¸€ä¸ªå¥å·ã€é—®å·æˆ–æ„Ÿå¹å·å¤„æˆªæ–­
        for delimiter in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']:
            last_delimiter = truncated.rfind(delimiter)
            if last_delimiter > max_length * 0.8:  # ç¡®ä¿ä¸ä¼šæˆªæ‰å¤ªå¤šå†…å®¹
                return truncated[:last_delimiter + 1]
        
        # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„åˆ†å‰²ç‚¹ï¼Œå°±åœ¨æœ€åä¸€ä¸ªç©ºæ ¼å¤„æˆªæ–­
        last_space = truncated.rfind(' ')
        if last_space > max_length * 0.8:
            return truncated[:last_space] + "..."
        
        return truncated + "..."
    

    
    def _generate_report_markdown(self, category: str, analysis_results: List[Dict[str, Any]], 
                                 period_start: datetime, period_end: datetime) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        
        # æŠ¥å‘Šæ ‡é¢˜
        title = f"ğŸ“ˆ [{category}] æ¿å—24å°æ—¶çƒ­ç‚¹æŠ¥å‘Š"
        
        # æ—¶é—´ä¿¡æ¯
        start_str = period_start.strftime('%Y-%m-%d %H:%M:%S')
        end_str = period_end.strftime('%Y-%m-%d %H:%M:%S')
        generate_time = self.get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')
        
        # æ„å»ºæŠ¥å‘Šå†…å®¹
        report_lines = [
            f"# {title}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {generate_time}*  ",
            f"*æ•°æ®èŒƒå›´: {start_str} - {end_str}*",
            "",
            "---",
            "",
            f"## ğŸ”¥ æœ¬æ—¶æ®µçƒ­é—¨ä¸»é¢˜ Top {len(analysis_results)}",
            ""
        ]
        
        # æ·»åŠ æ¯ä¸ªä¸»é¢˜çš„åˆ†æ
        for i, result in enumerate(analysis_results, 1):
            report_lines.extend([
                f"### {i}. {result['title']}",
                f"- **åŸå§‹é“¾æ¥**: [{result['url']}]({result['url']})",
                f"- **çƒ­åº¦åˆ†æ•°**: {result['hotness_score']:.2f}",
                ""
            ])
            
            # è§£æLLMåˆ†æç»“æœ
            analysis_content = result.get('analysis', '')
            if analysis_content:
                # ç®€å•è§£æåˆ†æç»“æœï¼Œæå–æ‘˜è¦å’Œå…³é”®ç‚¹
                lines = analysis_content.split('\n')
                current_section = None
                
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    if line.startswith('## æ ¸å¿ƒæ‘˜è¦') or line.startswith('## æ‘˜è¦'):
                        current_section = 'summary'
                        continue
                    elif line.startswith('## å…³é”®ä¿¡æ¯ç‚¹') or line.startswith('## å…³é”®ç‚¹'):
                        current_section = 'points'
                        report_lines.append("- **å…³é”®è®¨è®ºç‚¹**:")
                        continue
                    elif line.startswith('##'):
                        current_section = None
                        continue
                    
                    if current_section == 'summary' and not line.startswith('-'):
                        # æ‘˜è¦å†…å®¹
                        if line:
                            report_lines.append(f"  > {line}")
                    elif current_section == 'points' and line.startswith('-'):
                        # å…³é”®ä¿¡æ¯ç‚¹
                        point = line[1:].strip()
                        if point:
                            report_lines.append(f"  {line}")
                
                # å¦‚æœæ²¡æœ‰æˆåŠŸè§£æï¼Œç›´æ¥æ˜¾ç¤ºåŸå§‹åˆ†æç»“æœ
                if current_section is None and analysis_content:
                    report_lines.extend([
                        "- **åˆ†æç»“æœ**:",
                        f"  > {analysis_content.replace(chr(10), chr(10) + '  > ')}"
                    ])
            
            # æŠ€æœ¯ä¿¡æ¯ï¼ˆå¯é€‰æ˜¾ç¤ºï¼‰
            if result.get('provider'):
                report_lines.append(f"- *åˆ†æå¼•æ“: {result['provider']} ({result.get('model', 'unknown')})*")
            
            report_lines.extend(["", "---", ""])
        
        # æŠ¥å‘Šå°¾éƒ¨
        report_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(analysis_results)} ä¸ªçƒ­é—¨ä¸»é¢˜",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        
        return "\n".join(report_lines)
    
    def _generate_unified_report_markdown(self, category: str, unified_analysis: Dict[str, Any],
                                         hot_topics_data: List[Dict[str, Any]],
                                         period_start: datetime, period_end: datetime) -> str:
        """ç”Ÿæˆç»Ÿä¸€åˆ†ææŠ¥å‘Šçš„Markdownæ ¼å¼ (V2.1)"""

        # æŠ¥å‘Šæ ‡é¢˜
        title = f"ğŸ“ˆ [{category}] ç¤¾åŒºæƒ…æŠ¥æ´å¯ŸæŠ¥å‘Š"

        # æ—¶é—´ä¿¡æ¯
        start_str = period_start.strftime('%Y-%m-%d %H:%M:%S')
        end_str = period_end.strftime('%Y-%m-%d %H:%M:%S')
        generate_time = self.get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')

        # è·å–AIåˆ†æå†…å®¹
        analysis_content = unified_analysis.get('analysis', 'åˆ†æå†…å®¹ç”Ÿæˆå¤±è´¥ã€‚')

        # æ„å»ºæŠ¥å‘Šå†…å®¹
        report_lines = [
            f"# {title}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {generate_time}*",
            f"*æ•°æ®èŒƒå›´: {start_str} - {end_str}*",
            "",
            "---",
            "",
            analysis_content,  # æ’å…¥LLMç”Ÿæˆçš„å®Œæ•´æŠ¥å‘Š
            "",
            "---",
            "",
            "## ğŸ“š æ¥æºæ¸…å• (Source List)",
            ""
        ]

        # ç”Ÿæˆæ¥æºæ¸…å•
        for i, topic_data in enumerate(hot_topics_data, 1):
            topic_info = topic_data['topic']
            report_lines.append(
                f"- **[T{i}]**: [{topic_info['title']}]({topic_info['url']})"
            )

        report_lines.extend(["", "---", ""])

        # æŠ€æœ¯ä¿¡æ¯
        if unified_analysis.get('provider'):
            report_lines.append(
                f"*åˆ†æå¼•æ“: {unified_analysis['provider']} ({unified_analysis.get('model', 'unknown')})*"
            )

        report_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(hot_topics_data)} ä¸ªçƒ­é—¨ä¸»é¢˜",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])

        return "\n".join(report_lines)

    async def generate_category_report(self, category: str = None, hours_back: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆçƒ­ç‚¹åˆ†ææŠ¥å‘Šï¼ˆä¸å†æŒ‰åˆ†ç±»ç­›é€‰ï¼Œä»æ‰€æœ‰æ•°æ®ä¸­è·å–çƒ­é—¨ä¸»é¢˜ï¼‰"""
        try:
            report_title = "å…¨ç«™çƒ­ç‚¹åˆ†ææŠ¥å‘Š" if category is None else f"{category} æ¿å—çƒ­ç‚¹åˆ†ææŠ¥å‘Š"
            self.logger.info(f"å¼€å§‹ç”Ÿæˆ {report_title} (å›æº¯ {hours_back} å°æ—¶)")
            
            # è®¾ç½®åˆ†ææ—¶é—´èŒƒå›´
            end_time = self.get_beijing_time()
            start_time = end_time - timedelta(hours=hours_back)
            
            # è·å–æ‰€æœ‰çƒ­é—¨ä¸»é¢˜ï¼ˆä¸æŒ‰åˆ†ç±»ç­›é€‰ï¼‰
            hot_topics = self.db.get_hot_topics_all(
                limit=self.top_topics_per_category, 
                hours_back=hours_back
            )
            
            if not hot_topics:
                self.logger.warning(f"è¿‡å» {hours_back} å°æ—¶å†…æ²¡æœ‰çƒ­é—¨ä¸»é¢˜")
                return {
                    'success': True,
                    'category': category or 'å…¨ç«™',
                    'topics_analyzed': 0,
                    'message': f'è¿‡å» {hours_back} å°æ—¶å†…æš‚æ— çƒ­é—¨å†…å®¹'
                }
            
            self.logger.info(f"æ‰¾åˆ° {len(hot_topics)} ä¸ªçƒ­é—¨ä¸»é¢˜ï¼Œå¼€å§‹è·å–è¯¦ç»†æ•°æ®")
            
            # è·å–æ‰€æœ‰ä¸»é¢˜çš„è¯¦ç»†æ•°æ®
            hot_topics_data = []
            for i, topic in enumerate(hot_topics, 1):
                self.logger.info(f"è·å–ç¬¬ {i}/{len(hot_topics)} ä¸ªä¸»é¢˜è¯¦ç»†æ•°æ®: {topic.get('title', 'æœªçŸ¥æ ‡é¢˜')[:50]}...")
                
                # è·å–ä¸»é¢˜çš„è¯¦ç»†å†…å®¹
                topic_data = self.db.get_topic_posts_for_analysis(
                    topic['id'], 
                    limit=self.top_replies_per_topic
                )
                
                if topic_data:
                    hot_topics_data.append(topic_data)
                    self.logger.info(f"ä¸»é¢˜ {i}/{len(hot_topics)} æ•°æ®è·å–æˆåŠŸ")
                else:
                    self.logger.warning(f"ä¸»é¢˜ {i}/{len(hot_topics)} æ— æ³•è·å–è¯¦ç»†æ•°æ®")
            
            if not hot_topics_data:
                self.logger.warning(f"æ‰€æœ‰ä¸»é¢˜éƒ½æ— æ³•è·å–è¯¦ç»†æ•°æ®")
                return {
                    'success': False,
                    'error': 'æ— æ³•è·å–ä¸»é¢˜è¯¦ç»†æ•°æ®',
                    'category': category,
                    'topics_analyzed': 0
                }
            
            self.logger.info(f"å…±è·å–åˆ° {len(hot_topics_data)} ä¸ªä¸»é¢˜çš„è¯¦ç»†æ•°æ®ï¼Œå¼€å§‹ç»Ÿä¸€LLMåˆ†æ")
            
            # ä½¿ç”¨ç»Ÿä¸€LLMåˆ†æ
            unified_result = self._analyze_all_topics_with_llm(hot_topics_data)
            
            if not unified_result or not unified_result.get('success'):
                self.logger.warning(f"{category or 'å…¨ç«™'} æ¿å—çš„ç»Ÿä¸€ä¸»é¢˜åˆ†æå¤±è´¥")
                return {
                    'success': False,
                    'error': f'{category or "å…¨ç«™"} æ¿å—ä¸»é¢˜åˆ†æå¤±è´¥',
                    'category': category,
                    'topics_analyzed': 0
                }
            
            self.logger.info(f"ç»Ÿä¸€åˆ†æå®Œæˆï¼Œåˆ†æäº† {len(hot_topics_data)} ä¸ªä¸»é¢˜")
            
            # ç”ŸæˆMarkdownæŠ¥å‘Š
            report_content = self._generate_unified_report_markdown(
                category=category or 'å…¨ç«™',
                unified_analysis=unified_result,
                hot_topics_data=hot_topics_data,
                period_start=start_time,
                period_end=end_time
            )
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
            report_data = {
                'category': category or 'å…¨ç«™',
                'report_type': 'hotspot',
                'analysis_period_start': start_time,
                'analysis_period_end': end_time,
                'topics_analyzed': len(hot_topics_data),
                'report_title': f'[{category or "å…¨ç«™"}] ç¤¾åŒºæƒ…æŠ¥æ´å¯ŸæŠ¥å‘Š',
                'report_content': report_content
            }
            
            report_id = self.db.save_report(report_data)
            
            result = {
                'success': True,
                'category': category or 'å…¨ç«™',
                'report_id': report_id,
                'topics_analyzed': len(hot_topics_data),
                'total_topics_found': len(hot_topics),
                'analysis_period': {
                    'start': start_time,
                    'end': end_time,
                    'hours_back': hours_back
                },
                'report_preview': report_content[:500] + "..." if len(report_content) > 500 else report_content
            }
            
            self.logger.info(f"{category or 'å…¨ç«™'} åˆ†æå®Œæˆ: åˆ†æäº† {len(hot_topics_data)}/{len(hot_topics)} ä¸ªä¸»é¢˜ï¼ŒæŠ¥å‘ŠID: {report_id}")
            return result
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆ {category or 'å…¨ç«™'} æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return {
                'success': False,
                'error': str(e),
                'category': category or 'å…¨ç«™',
                'topics_analyzed': 0
            }
    
    async def generate_all_categories_report(self, hours_back: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆå…¨ç«™çƒ­ç‚¹åˆ†ææŠ¥å‘Šï¼ˆä¸å†æŒ‰åˆ†ç±»ï¼‰"""
        try:
            self.logger.info(f"å¼€å§‹ç”Ÿæˆå…¨ç«™çƒ­ç‚¹åˆ†ææŠ¥å‘Š (å›æº¯ {hours_back} å°æ—¶)")
            
            # ç›´æ¥ç”Ÿæˆä¸€ä¸ªå…¨ç«™æŠ¥å‘Š
            result = await self.generate_category_report(category=None, hours_back=hours_back)
            
            if result.get('success'):
                # åŒ…è£…æˆä¸åŸæ ¼å¼å…¼å®¹çš„ç»“æ„
                return {
                    'success': True,
                    'total_categories': 1,
                    'successful_reports': 1,
                    'failed_reports': 0,
                    'total_topics_analyzed': result.get('topics_analyzed', 0),
                    'reports': [result],
                    'failures': [],
                    'generation_time': self.get_beijing_time()
                }
            else:
                return {
                    'success': False,
                    'total_categories': 1,
                    'successful_reports': 0,
                    'failed_reports': 1,
                    'total_topics_analyzed': 0,
                    'reports': [],
                    'failures': [{
                        'category': 'å…¨ç«™',
                        'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
                    }],
                    'generation_time': self.get_beijing_time()
                }
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå…¨ç«™æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return {
                'success': False,
                'error': str(e),
                'reports': []
            }
    
    def _format_all_topics_for_analysis(self, hot_topics_data: List[Dict[str, Any]]) -> str:
        """å°†æ‰€æœ‰çƒ­é—¨ä¸»é¢˜åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æ¡£ç”¨äºLLMç»Ÿä¸€åˆ†æ (V2.1)"""
        content_parts = []
        
        # æ·»åŠ æ–‡æ¡£å¤´éƒ¨
        content_parts.extend([
            "=== çƒ­é—¨ä¸»é¢˜ç»¼åˆåˆ†ææ–‡æ¡£ ===",
            f"æ€»è®¡ {len(hot_topics_data)} ä¸ªçƒ­é—¨ä¸»é¢˜",
            "",
        ])
        
        # æŒ‰çƒ­åº¦æ’åºå¤„ç†æ¯ä¸ªä¸»é¢˜
        for i, topic_data in enumerate(hot_topics_data, 1):
            topic_info = topic_data['topic']
            main_post = topic_data.get('main_post')
            replies = topic_data.get('replies', [])
            
            content_parts.extend([
                f"\n### [Source: T{i}] {topic_info['title']}",
                f"çƒ­åº¦åˆ†æ•°: {topic_info.get('hotness_score', 0):.2f}",
                f"åˆ†ç±»: {topic_info.get('category', 'æœªçŸ¥')}",
                f"å›å¤æ•°: {topic_info.get('reply_count', 0)}",
                f"æµè§ˆæ•°: {topic_info.get('view_count', 0)}",
                f"æ€»ç‚¹èµæ•°: {topic_info.get('total_like_count', 0)}",
                f"URL: {topic_info.get('url', '')}",
                ""
            ])
            
            # ä¸»è´´å†…å®¹ï¼ˆç²¾ç®€ç‰ˆï¼‰
            if main_post and main_post.get('content_raw'):
                main_content = main_post['content_raw'].strip()
                if main_content:
                    # é™åˆ¶ä¸»è´´å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿
                    if len(main_content) > 800:
                        main_content = main_content[:800] + "..."
                    content_parts.extend([
                        "**ä¸»è´´å†…å®¹:**",
                        main_content,
                        ""
                    ])
            
            # çƒ­é—¨å›å¤ï¼ˆç²¾ç®€ç‰ˆï¼‰
            if replies:
                content_parts.append("**çƒ­é—¨å›å¤:**")
                # é™åˆ¶å›å¤æ•°é‡å’Œé•¿åº¦
                for j, reply in enumerate(replies[:min(3, self.top_replies_per_topic)], 1):
                    if reply.get('content_raw'):
                        reply_content = reply['content_raw'].strip()
                        if reply_content:
                            # é™åˆ¶å›å¤å†…å®¹é•¿åº¦
                            if len(reply_content) > 200:
                                reply_content = reply_content[:200] + "..."
                            content_parts.extend([
                                f"{j}. (ç‚¹èµ: {reply.get('like_count', 0)}): {reply_content}",
                                ""
                            ])
            
            content_parts.append("---\n")  # ä¸»é¢˜åˆ†å‰²çº¿
        
        # åˆå¹¶æ‰€æœ‰å†…å®¹
        full_content = "\n".join(content_parts)
        
        # å¦‚æœå†…å®¹è¿‡é•¿ï¼Œè¿™é‡Œä¸å†æˆªæ–­ï¼Œè®©LLMçœ‹åˆ°æ‰€æœ‰ä¸»é¢˜
        self.logger.info(f"æ ¼å¼åŒ–åçš„ä¸»é¢˜å†…å®¹æ€»é•¿åº¦: {len(full_content)} å­—ç¬¦")
        return full_content
    
    def _get_unified_analysis_prompt_template(self) -> str:
        """è·å–ç»Ÿä¸€åˆ†æçš„æç¤ºè¯æ¨¡æ¿ï¼ˆV2.2 - æ··åˆæ¨¡å¼ï¼‰"""
        return """ä½ æ˜¯ä¸€ä½ä¸ºé¡¶çº§æŠ€æœ¯å…¬å¸æœåŠ¡çš„èµ„æ·±è¡Œä¸šåˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä»¥ä¸‹æ¥è‡ªä¸€çº¿å¼€å‘è€…ç¤¾åŒºçš„ã€å·²ç¼–å·çš„åŸå§‹è®¨è®ºææ–™ï¼Œå¹¶ä¸ºæŠ€æœ¯å†³ç­–è€…æ’°å†™ä¸€ä»½å¾ªåºæ¸è¿›ã€å¯è¿½æº¯æ¥æºçš„æƒ…æŠ¥ç®€æŠ¥ã€‚

**åŸå§‹è®¨è®ºææ–™:**
{content}

---

**ä½ çš„åˆ†æä»»åŠ¡:**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ä¸¤ä¸ªé˜¶æ®µè¿›è¡Œåˆ†æå’Œå†…å®¹ç”Ÿæˆã€‚**è‡³å…³é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼šä½ çš„æ¯ä¸€æ¡åˆ†æã€æ´å¯Ÿå’Œå»ºè®®éƒ½å¿…é¡»åœ¨ç»“å°¾å¤„ä½¿ç”¨ `[Source: T_n]` æˆ– `[Sources: T_n, T_m]` çš„æ ¼å¼æ˜ç¡®æ ‡æ³¨å…¶ä¿¡æ¯æ¥æºã€‚**

**ç¬¬ä¸€é˜¶æ®µï¼šçƒ­é—¨ä¸»é¢˜é€Ÿè§ˆ (Top Topics Summary)**
é¦–å…ˆï¼Œè¯·é€šè¯»æ‰€æœ‰ææ–™ï¼Œå¯¹æ¯ä¸ªçƒ­é—¨ä¸»é¢˜è¿›è¡Œç®€æ˜æ‰¼è¦çš„æ€»ç»“ã€‚

**ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦æƒ…æŠ¥æ´å¯Ÿ (In-depth Intelligence Report)**
åœ¨å®Œæˆé€Ÿè§ˆåï¼Œè¯·è½¬æ¢è§†è§’ï¼ŒåŸºäºç¬¬ä¸€é˜¶æ®µä½ æ€»ç»“çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè¿›è¡Œæ›´é«˜å±‚çº§çš„è¶‹åŠ¿åˆ†æå’Œæ´å¯Ÿæç‚¼ã€‚

---

**è¯·ä¸¥æ ¼éµç…§ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºå®Œæ•´æŠ¥å‘Š:**

# ğŸ“ˆ ç¤¾åŒºçƒ­ç‚¹ä¸æƒ…æŠ¥æ´å¯ŸæŠ¥å‘Š

## ğŸ”¥ æœ¬æ—¶æ®µçƒ­é—¨ä¸»é¢˜é€Ÿè§ˆ

[åœ¨æ­¤å¤„ç½—åˆ—æœ€é‡è¦çš„5-10ä¸ªçƒ­é—¨ä¸»é¢˜çš„é€Ÿè§ˆ]

### **1. [ä¸»é¢˜Açš„æ ‡é¢˜]**
*   **æ ¸å¿ƒå†…å®¹**: [å¯¹è¯¥ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹ã€è®¨è®ºç„¦ç‚¹å’Œä¸»è¦ç»“è®ºè¿›è¡Œ3-5å¥è¯çš„æ‘˜è¦ã€‚] [Source: T_n]

### **2. [ä¸»é¢˜Bçš„æ ‡é¢˜]**
*   **æ ¸å¿ƒå†…å®¹**: [å¯¹è¯¥ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹ã€è®¨è®ºç„¦ç‚¹å’Œä¸»è¦ç»“è®ºè¿›è¡Œ3-5å¥è¯çš„æ‘˜è¦ã€‚] [Source: T_m]

...(ä»¥æ­¤ç±»æ¨)

---

## ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ (Executive Summary)

*   **[æ´å¯Ÿä¸€]**: [ç”¨ä¸€å¥è¯é«˜åº¦æ¦‚æ‹¬ä½ å‘ç°çš„æœ€é‡è¦çš„è¶‹åŠ¿æˆ–æ´å¯Ÿã€‚ä¾‹å¦‚ï¼šå¯¹ä½ä»£ç /æ— ä»£ç å¹³å°çš„è®¨è®ºæ¿€å¢ï¼Œåæ˜ å‡ºå¼€å‘æ•ˆç‡å·²æˆä¸ºç¤¾åŒºæ ¸å¿ƒå…³åˆ‡ç‚¹ã€‚] [Sources: T1, T5, T8]
*   **[æ´å¯ŸäºŒ]**: [ç¬¬äºŒä¸ªé‡è¦æ´å¯Ÿã€‚ä¾‹å¦‚ï¼šAI Agentçš„å®ç°å’Œåº”ç”¨æˆä¸ºæ–°çš„æŠ€æœ¯ç„¦ç‚¹ï¼Œå¤šä¸ªçƒ­é—¨é¡¹ç›®å›´ç»•æ­¤å±•å¼€ã€‚] [Sources: T2, T9]
*   **[æ´å¯Ÿä¸‰]**: [ç¬¬ä¸‰ä¸ªé‡è¦æ´å¯Ÿã€‚] [Source: T4]

## ğŸ” è¶‹åŠ¿ä¸ä¿¡å·åˆ†æ (Trends & Signals Analysis)

### ğŸš€ æ–°å…´æŠ€æœ¯ä¸å·¥å…·é£å‘
*   **[æŠ€æœ¯/å·¥å…·A]**: [æè¿°å®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒç°åœ¨å¾ˆçƒ­é—¨ï¼Œä»¥åŠåœ¨è®¨è®ºä¸­æ˜¯å¦‚ä½•ä½“ç°çš„ã€‚] [Source: T3]
*   **[æŠ€æœ¯/å·¥å…·B]**: [åŒä¸Šã€‚] [Source: T7]

### ğŸ”— è®¨è®ºçƒ­ç‚¹çš„å†…åœ¨å…³è”
*   **[å…³è”æ€§åˆ†æ]**: [è¯¦ç»†é˜è¿°ä½ å‘ç°çš„ä¸åŒçƒ­ç‚¹ä¹‹é—´çš„è”ç³»ã€‚ä¾‹å¦‚ï¼šå¯¹â€œXXæ¡†æ¶æ€§èƒ½ç“¶é¢ˆâ€çš„æŠ±æ€¨ï¼ˆä¸»é¢˜Aï¼‰ä¸â€œYYè½»é‡çº§æ›¿ä»£æ–¹æ¡ˆâ€çš„å‡ºç°ï¼ˆä¸»é¢˜Bï¼‰å½¢æˆäº†å‘¼åº”ï¼Œå…±åŒæŒ‡å‘äº†å‰ç«¯å¼€å‘çš„è½»é‡åŒ–è¶‹åŠ¿ã€‚] [Sources: T1, T6]

### âš ï¸ æ™®éç—›ç‚¹ä¸æ½œåœ¨éœ€æ±‚
*   **[ç—›ç‚¹ä¸€]**: [æè¿°ç¤¾åŒºå¼€å‘è€…æ™®éé‡åˆ°çš„ä¸€ä¸ªé—®é¢˜æˆ–æŒ‘æˆ˜ã€‚] [Source: T5]
*   **[ç—›ç‚¹äºŒ]**: [åŒä¸Šã€‚] [Source: T10]

##  actionable å»ºè®® (Actionable Recommendations)

*   **å¯¹äºå¼€å‘è€…**: [åŸºäºä»¥ä¸Šåˆ†æï¼Œç»™ä¸ªäººå¼€å‘è€…æå‡º1-2æ¡å…·ä½“å»ºè®®ã€‚ä¾‹å¦‚ï¼šå»ºè®®å…³æ³¨XXæŠ€æœ¯ï¼Œå°è¯•å°†YYå·¥å…·é›†æˆåˆ°å½“å‰å·¥ä½œæµä¸­ä»¥æé«˜æ•ˆç‡ã€‚] [Sources: T3, T7]
*   **å¯¹äºæŠ€æœ¯å›¢é˜Ÿ**: [ç»™æŠ€æœ¯å›¢é˜Ÿæˆ–å†³ç­–è€…æå‡º1-2æ¡å»ºè®®ã€‚ä¾‹å¦‚ï¼šå»ºè®®è¯„ä¼°å¼•å…¥XXè§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§ï¼Œä»¥è§£å†³å›¢é˜Ÿåœ¨YYæ–¹é¢é‡åˆ°çš„æ™®éé—®é¢˜ã€‚] [Source: T5]

---

## ğŸ“š æ¥æºæ¸…å• (Source List)
[è¿™é‡Œç”±ç¨‹åºè‡ªåŠ¨ç”Ÿæˆï¼Œä½ ä¸éœ€è¦å¡«å†™è¿™éƒ¨åˆ†ã€‚]
"""
    
    def _analyze_all_topics_with_llm(self, hot_topics_data: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨LLMå¯¹æ‰€æœ‰ä¸»é¢˜è¿›è¡Œç»Ÿä¸€åˆ†æ"""
        try:
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
            if not self.llm:
                self.logger.warning("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return None
            
            # åˆå¹¶æ‰€æœ‰ä¸»é¢˜å†…å®¹
            content = self._format_all_topics_for_analysis(hot_topics_data)
            
            # è·å–ç»Ÿä¸€åˆ†ææç¤ºè¯æ¨¡æ¿
            prompt_template = self._get_unified_analysis_prompt_template()
            
            self.logger.info(f"å¼€å§‹å¯¹ {len(hot_topics_data)} ä¸ªä¸»é¢˜è¿›è¡Œç»Ÿä¸€LLMåˆ†æï¼Œå†…å®¹æ€»é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è°ƒç”¨LLMåˆ†æ
            result = self.llm.analyze_content(content, prompt_template)
            
            if result.get('success'):
                return {
                    'success': True,
                    'topics_count': len(hot_topics_data),
                    'analysis': result['content'],
                    'provider': result.get('provider'),
                    'model': result.get('model')
                }
            else:
                self.logger.warning(f"LLMç»Ÿä¸€åˆ†æå¤±è´¥: {result.get('error')}")
                return None
                
        except Exception as e:
            self.logger.error(f"ç»Ÿä¸€åˆ†æä¸»é¢˜æ—¶å‡ºé”™: {e}")
            return None


# å…¨å±€æŠ¥å‘Šç”Ÿæˆå™¨å®ä¾‹
report_generator = ReportGenerator()