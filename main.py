#!/usr/bin/env python3
"""
Linux.doè®ºå›è‡ªåŠ¨åŒ–æ•°æ®è¿ç»´ç³»ç»Ÿ
ä¸»æ‰§è¡Œè„šæœ¬
"""
import sys
import argparse
import json
from datetime import datetime, timezone, timedelta

from src.scheduler import scheduler


def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰"""
    utc_time = datetime.now(timezone.utc)
    beijing_time = utc_time + timedelta(hours=8)
    return beijing_time.replace(tzinfo=None)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Linux.doè®ºå›è‡ªåŠ¨åŒ–æ•°æ®è¿ç»´ç³»ç»Ÿ')
    parser.add_argument('--task', choices=['crawl', 'cleanup', 'stats', 'analysis', 'report', 'full'], 
                       default='crawl', help='è¦æ‰§è¡Œçš„ä»»åŠ¡ç±»å‹')
    parser.add_argument('--retention-days', type=int, 
                       help='æ•°æ®ä¿ç•™å¤©æ•°ï¼ˆä»…ç”¨äºcleanupä»»åŠ¡ï¼‰')
    parser.add_argument('--output', choices=['json', 'text'], default='text',
                       help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--concurrent', action='store_true', default=True,
                       help='ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--serial', action='store_true',
                       help='ä½¿ç”¨ä¸²è¡Œæ¨¡å¼ï¼ˆè¦†ç›–--concurrentï¼‰')
    parser.add_argument('--hours-back', type=int, default=24,
                       help='åˆ†æä»»åŠ¡å›æº¯çš„å°æ—¶æ•°ï¼ˆé»˜è®¤24å°æ—¶ï¼‰')
    parser.add_argument('--analyze-all', action='store_true',
                       help='åˆ†ææ‰€æœ‰ä¸»é¢˜ï¼ˆä»…ç”¨äºanalysisä»»åŠ¡ï¼‰')
    parser.add_argument('--category', type=str,
                       help='æŒ‡å®šæ¿å—åˆ†ç±»ï¼ˆä»…ç”¨äºreportä»»åŠ¡ï¼‰')
    
    args = parser.parse_args()
    
    print(f"Linux.doè®ºå›è‡ªåŠ¨åŒ–æ•°æ®è¿ç»´ç³»ç»Ÿ")
    print(f"æ‰§è¡Œæ—¶é—´: {get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ‰§è¡Œä»»åŠ¡: {args.task}")
    print("-" * 50)
    
    # ç¡®å®šæ˜¯å¦ä½¿ç”¨å¹¶å‘æ¨¡å¼
    use_concurrent = args.concurrent and not args.serial
    
    # æ‰§è¡Œå¯¹åº”ä»»åŠ¡
    if args.task == 'crawl':
        result = await scheduler.run_crawl_task(use_concurrent=use_concurrent)
    elif args.task == 'cleanup':
        result = scheduler.run_cleanup_task(args.retention_days)
    elif args.task == 'stats':
        result = scheduler.run_stats_task()
    elif args.task == 'analysis':
        result = scheduler.run_analysis_task(args.hours_back, args.analyze_all)
    elif args.task == 'report':
        result = await scheduler.run_report_task(args.category, args.hours_back)
    elif args.task == 'full':
        result = await scheduler.run_full_maintenance()
    else:
        print(f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {args.task}")
        sys.exit(1)
    
    # è¾“å‡ºç»“æœ
    if args.output == 'json':
        print(json.dumps(result, indent=2, ensure_ascii=False, default=str))
    else:
        print_result(result, args.task)
    
    # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
    if result.get('success', False):
        print("\nâœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
        sys.exit(0)
    else:
        print(f"\nâŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        sys.exit(1)


def print_result(result: dict, task_type: str):
    """æ‰“å°ç»“æœ"""
    if not result.get('success', False):
        print(f"âŒ ä»»åŠ¡å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return
    
    if task_type == 'crawl':
        print(f"âœ… çˆ¬å–ä»»åŠ¡å®Œæˆ")
        print(f"   å‘ç°ä¸»é¢˜: {result.get('topics_found', 0)} ä¸ª")
        print(f"   æˆåŠŸçˆ¬å–: {result.get('topics_crawled', 0)} ä¸ª")
        if 'success_rate' in result:
            print(f"   æˆåŠŸç‡: {result['success_rate']}")
    
    elif task_type == 'cleanup':
        cleanup_result = result.get('cleanup_result', {})
        orphan_result = result.get('orphan_result', {})
        
        print(f"âœ… æ¸…ç†ä»»åŠ¡å®Œæˆ")
        print(f"   åˆ é™¤è¿‡æœŸä¸»é¢˜: {cleanup_result.get('deleted_topics', 0)} ä¸ª")
        print(f"   æ¸…ç†å­¤ç«‹å›å¤: {orphan_result.get('orphaned_posts_deleted', 0)} ä¸ª")
        print(f"   ä¿®å¤å­¤ç«‹ä½œè€…: {orphan_result.get('orphaned_topic_authors_fixed', 0)} + {orphan_result.get('orphaned_post_authors_fixed', 0)} ä¸ª")
        
        if 'stats_after' in result:
            stats = result['stats_after']
            print(f"   å½“å‰æ•°æ®é‡: ç”¨æˆ· {stats.get('users_count', 0)}, ä¸»é¢˜ {stats.get('topics_count', 0)}, å›å¤ {stats.get('posts_count', 0)}")
    
    elif task_type == 'stats':
        stats = result.get('stats', {})
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯")
        print(f"   ç”¨æˆ·æ•°é‡: {stats.get('users_count', 0)}")
        print(f"   ä¸»é¢˜æ•°é‡: {stats.get('topics_count', 0)}")
        print(f"   å›å¤æ•°é‡: {stats.get('posts_count', 0)}")
        print(f"   ä»Šæ—¥ä¸»é¢˜: {stats.get('today_topics', 0)}")
        if stats.get('latest_activity'):
            print(f"   æœ€æ–°æ´»åŠ¨: {stats['latest_activity']}")
        if stats.get('oldest_activity'):
            print(f"   æœ€æ—§æ•°æ®: {stats['oldest_activity']}")
    
    elif task_type == 'analysis':
        print(f"âœ… çƒ­åº¦åˆ†æå®Œæˆ")
        print(f"   åˆ†æä¸»é¢˜: {result.get('analyzed_topics', result.get('updated_scores', 0))} ä¸ª")
        print(f"   æ›´æ–°ç‚¹èµ: {result.get('updated_likes', 0)} ä¸ª")
        print(f"   æ›´æ–°çƒ­åº¦: {result.get('updated_scores', 0)} ä¸ª")
        
        stats_result = result.get('hotness_stats', {})
        if stats_result.get('success'):
            stats = stats_result
            print(f"   å¹³å‡çƒ­åº¦: {stats.get('avg_hotness', 0)}")
            print(f"   æœ€é«˜çƒ­åº¦: {stats.get('max_hotness', 0)}")
    
    elif task_type == 'report':
        print(f"âœ… æ™ºèƒ½åˆ†ææŠ¥å‘Šå®Œæˆ")
        if 'category' in result:
            # å•ä¸ªæ¿å—æŠ¥å‘Š
            print(f"   æ¿å—: {result.get('category')}")
            print(f"   åˆ†æä¸»é¢˜: {result.get('topics_analyzed', 0)} ä¸ª")
            if result.get('report_id'):
                print(f"   æŠ¥å‘ŠID: {result.get('report_id')}")
            
            # æ˜¾ç¤ºNotionæ¨é€ç»“æœ
            notion_push = result.get('notion_push')
            if notion_push:
                if notion_push.get('success'):
                    print(f"   ğŸ“„ Notionæ¨é€: æˆåŠŸ - {notion_push.get('page_url')}")
                else:
                    print(f"   ğŸ“„ Notionæ¨é€: å¤±è´¥ - {notion_push.get('error')}")
        else:
            # æ‰€æœ‰æ¿å—æŠ¥å‘Š
            print(f"   æˆåŠŸæ¿å—: {result.get('successful_reports', 0)}/{result.get('total_categories', 0)}")
            print(f"   æ€»åˆ†æä¸»é¢˜: {result.get('total_topics_analyzed', 0)} ä¸ª")
            if result.get('failures'):
                print(f"   å¤±è´¥æ¿å—: {len(result['failures'])} ä¸ª")
            
            # æ˜¾ç¤ºNotionæ¨é€ç»Ÿè®¡
            reports = result.get('reports', [])
            notion_success = sum(1 for r in reports if r.get('notion_push', {}).get('success'))
            if notion_success > 0:
                print(f"   ğŸ“„ Notionæ¨é€: {notion_success}/{len(reports)} ä¸ªæŠ¥å‘ŠæˆåŠŸæ¨é€")
    
    elif task_type == 'full':
        results = result.get('results', {})
        print(f"âœ… å®Œæ•´ç»´æŠ¤ä»»åŠ¡å®Œæˆ")
        
        # çˆ¬å–ç»“æœ
        crawl_result = results.get('crawl', {})
        if crawl_result.get('success'):
            print(f"   çˆ¬å–: å‘ç° {crawl_result.get('topics_found', 0)} ä¸ªä¸»é¢˜ï¼ŒæˆåŠŸ {crawl_result.get('topics_crawled', 0)} ä¸ª")
        
        # æ¸…ç†ç»“æœ
        cleanup_result = results.get('cleanup', {})
        if cleanup_result.get('success'):
            cleanup_data = cleanup_result.get('cleanup_result', {})
            print(f"   æ¸…ç†: åˆ é™¤ {cleanup_data.get('deleted_topics', 0)} ä¸ªè¿‡æœŸä¸»é¢˜")
        
        # ç»Ÿè®¡ç»“æœ
        stats_result = results.get('stats', {})
        if stats_result.get('success'):
            stats = stats_result.get('stats', {})
            print(f"   ç»Ÿè®¡: ç”¨æˆ· {stats.get('users_count', 0)}, ä¸»é¢˜ {stats.get('topics_count', 0)}, å›å¤ {stats.get('posts_count', 0)}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())